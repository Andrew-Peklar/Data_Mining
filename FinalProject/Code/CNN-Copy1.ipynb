{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet-Style Deep Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\tflearn\\initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.metrics import Accuracy\n",
    "\n",
    "acc = Accuracy()\n",
    "network = input_data(shape=[None, 100, 100, 3])\n",
    "\n",
    "# Conv layers ------------------------------------\n",
    "network = conv_2d(network, 64, 3, strides=1, activation='elu')\n",
    "network = max_pool_2d(network, 2, strides=2)\n",
    "network = conv_2d(network, 64, 3, strides=1, activation='elu')\n",
    "network = max_pool_2d(network, 2, strides=2)\n",
    "network = conv_2d(network, 64, 3, strides=1, activation='elu')\n",
    "network = conv_2d(network, 64, 3, strides=1, activation='elu')\n",
    "network = conv_2d(network, 64, 3, strides=1, activation='elu')\n",
    "network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "# Fully Connected Layers -------------------------\n",
    "network = fully_connected(network, 1024, activation='tanh')\n",
    "network = dropout(network, 0.5)\n",
    "network = fully_connected(network, 1024, activation='tanh')\n",
    "network = dropout(network, 0.5)\n",
    "\n",
    "# CHANGE BELOW FOR NUMBER OF CLASSES\n",
    "network = fully_connected(network, 57, activation='softmax')\n",
    "network = regression(network, optimizer='momentum', loss='categorical_crossentropy',\n",
    "learning_rate=0.001, metric=acc)\n",
    "\n",
    "model = tflearn.DNN(network, tensorboard_verbose=3, tensorboard_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"1\"\n",
    "#import deepneuralnet as net --> implemented above. If issue, save above as file and import\n",
    "import numpy as np\n",
    "from tflearn.data_utils import image_preloader\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = net.model\n",
    "data_file = 'klo.txt'\n",
    "X, Y = image_preloader(data_file, image_shape=(100, 100), mode='file', grayscale=False, categorical_labels=True, normalize=True)\n",
    "X = np.reshape(X, (-1, 100, 100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5499  | total loss: \u001b[1m\u001b[32m0.38085\u001b[0m\u001b[0m | time: 50.542s\n",
      "| Momentum | epoch: 250 | loss: 0.38085 - acc: 0.9518 -- iter: 1344/1359\n",
      "Training Step: 5500  | total loss: \u001b[1m\u001b[32m0.36071\u001b[0m\u001b[0m | time: 54.078s\n",
      "| Momentum | epoch: 250 | loss: 0.36071 - acc: 0.9550 | val_loss: 2.60135 - val_acc: 0.4882 -- iter: 1359/1359\n",
      "--\n",
      "INFO:tensorflow:C:\\Users\\andre\\Desktop\\Jupyter_Notebooks\\ZtrainedNet\\final-model.tfl is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, n_epoch=250, validation_set=0.2, show_metric=True)\n",
    "model.save('./ZtrainedNet/final-model.tfl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\andre\\Desktop\\Jupyter_Notebooks\\ZtrainedNet\\final-model.tfl\n"
     ]
    }
   ],
   "source": [
    "#model = net.model\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "path_to_model = './ZtrainedNet/final-model.tfl' \n",
    "model.load(path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = image_preloader('klo.txt', image_shape=(100,100), mode='file', grayscale=False, categorical_labels=True, normalize=True)\n",
    "X = np.reshape(X, (-1, 100, 100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8893466745144203\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.79      0.83        34\n",
      "          1       0.83      0.91      0.87        11\n",
      "          2       0.88      0.95      0.92       810\n",
      "          3       1.00      0.82      0.90        22\n",
      "          4       0.91      0.83      0.87        12\n",
      "          5       0.72      1.00      0.84        13\n",
      "          6       1.00      0.95      0.97        20\n",
      "          7       0.90      0.64      0.75        14\n",
      "          8       0.89      1.00      0.94        16\n",
      "          9       0.91      0.71      0.80        14\n",
      "         10       1.00      0.71      0.83        21\n",
      "         11       0.93      1.00      0.96        13\n",
      "         12       0.85      0.89      0.87        19\n",
      "         13       1.00      0.67      0.80        12\n",
      "         14       0.94      0.84      0.89        19\n",
      "         15       0.87      0.87      0.87        15\n",
      "         16       1.00      0.73      0.84        11\n",
      "         17       0.79      0.88      0.84        26\n",
      "         18       0.88      0.91      0.89        23\n",
      "         19       0.92      0.92      0.92        13\n",
      "         20       0.86      0.89      0.87        27\n",
      "         21       1.00      0.85      0.92        13\n",
      "         22       0.84      0.94      0.89        17\n",
      "         23       1.00      0.69      0.82        13\n",
      "         24       1.00      0.54      0.70        13\n",
      "         25       1.00      0.94      0.97        16\n",
      "         26       1.00      0.92      0.96        13\n",
      "         27       0.81      0.81      0.81        16\n",
      "         28       0.92      0.92      0.92        12\n",
      "         29       0.88      0.88      0.88        17\n",
      "         30       0.91      0.91      0.91        22\n",
      "         31       1.00      0.92      0.96        12\n",
      "         32       0.85      0.92      0.88        12\n",
      "         33       0.92      0.73      0.81        15\n",
      "         34       0.93      0.78      0.85        18\n",
      "         35       0.85      0.81      0.83        21\n",
      "         36       0.93      0.76      0.84        17\n",
      "         37       1.00      0.79      0.88        14\n",
      "         38       1.00      0.91      0.95        11\n",
      "         39       0.79      1.00      0.88        15\n",
      "         40       0.83      0.88      0.86        17\n",
      "         41       0.75      0.80      0.77        15\n",
      "         42       0.87      0.93      0.90        14\n",
      "         43       0.90      0.64      0.75        14\n",
      "         44       0.88      0.71      0.79        21\n",
      "         45       1.00      0.91      0.95        11\n",
      "         46       0.93      0.72      0.81        18\n",
      "         47       0.91      0.91      0.91        11\n",
      "         48       0.92      1.00      0.96        11\n",
      "         49       0.86      0.55      0.67        22\n",
      "         50       0.88      0.88      0.88        16\n",
      "         51       0.88      0.94      0.91        16\n",
      "         52       0.85      0.85      0.85        13\n",
      "         53       1.00      0.67      0.80        12\n",
      "         54       0.91      0.91      0.91        11\n",
      "         55       1.00      0.69      0.82        13\n",
      "         56       0.90      0.75      0.82        12\n",
      "\n",
      "avg / total       0.89      0.89      0.89      1699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_test = []\n",
    "for i in range(0, len(X)):\n",
    "    iimage = X[i]\n",
    "    icateg = Y[i]\n",
    "    result = model.predict([iimage])[0]\n",
    "    prediction = result.tolist().index(max(result))\n",
    "    reality = icateg.tolist().index(max(icateg))\n",
    "    y_pred.append(prediction)\n",
    "    y_test.append(reality)\n",
    "    #if prediction == reality:\n",
    "    #    print(\"image %d CORRECT \" % i, end='')\n",
    "    #else:\n",
    "    #    print(\"image %d WRONG \" % i, end='')\n",
    "    #print(result)\n",
    "print(\"Accuracy: \"+str(accuracy_score(y_test, y_pred)))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
